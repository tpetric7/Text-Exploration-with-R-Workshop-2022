# Quanteda korpusne funkcije {#sec-delavnica2}

```{r}
#| echo: false
#| fig-keep: 'all'
#| out-width: "100%"
#| fig-link: "https://quanteda.io/reference/textplot_network.html"

im <- magick::image_read("https://quanteda.io/reference/textplot_network-1.png")
im <- magick::image_background(im, color = "white")
magick::image_write(im, "pictures/quanteda_fcm_example.png")

knitr::include_graphics("pictures/quanteda_fcm_example.png", 
                        dpi = 300)
```

## Nalaganje knjižnic

```{r}
#| warning: false
#| message: false

library(readtext)
library(quanteda)
library(quanteda.textstats)
library(quanteda.textplots)
library(tidyverse)
library(tidytext)
library(wordcloud2)
library(udpipe)
library(janitor)
library(scales)
library(widyr)
library(syuzhet)
library(corpustools)
library(lubridate)
library(readxl)
library(writexl)

```

## Odpiranje tabele

```{r}
# iz prejšnje seje: csv datoteka z besedili in metapodatki
df <- read_csv2("data/slovenska_literatura_1968.csv") %>% 
  select(-`...1`, -n)
```

Čiščenje besedil v stolpcu *text*: precej je odvečnih presledkov, kar moti poizvedbe. 

```{r}
df <- df %>% mutate(text = str_squish(text))
```


## Izbor proznih del

```{r}
names(df)
```

```{r}
df_dolzina <- df %>% 
  filter(author_disp != "[Neznani avtor]") %>% 
  filter(text_type == "proza") %>% 
  group_by(title_disp, author_disp) %>% 
  summarise(dolzina = ntoken(text)) %>% 
  arrange(-dolzina)
```
```{r}
df_dolzina %>% 
  head(10) %>% 
  rmarkdown::paged_table()
```

```{r}
df_naslova <- df_dolzina[c(8, 9), ] %>% 
  pull(title_disp)
df_naslova
```

```{r}
df_izbor <- df %>% 
  filter(title_disp %in% df_naslova)

df_izbor %>% rmarkdown::paged_table()
```



## Quanteda korpus

Knjižnica `quanteda` ima nekaj zelo priročnih in hitrih funkcij za prikaz konkordanc in diagramov. 

S knjižnico `quanteda` bomo ustvarili korpus (`corpus`), ga razdrobili na manjše jezikovne enote (`tokens`) in pripravili matriko (`dfm`), ki vključuje besedila v vrsticah in besede (oz. tokens) v stolpcih.  

V sledečem programskem odstavku so gradniki, ki jih potrebujemo za statistične in grafične funkcije knjižnice `quanteda`.

```{r}
corp <- corpus(df_izbor, 
               text_field = "text", docid_field = "doc_id")
toks <- tokens(corp, remove_numbers = TRUE, remove_punct = T,
               remove_symbols = T, remove_url = T, 
               remove_separators = FALSE)
mat <- dfm(toks, padding = TRUE)

```
## Besedilna evidenca

```{r message=FALSE, warning=FALSE}
evidenca <- textstat_summary(corp)
evidenca %>% rmarkdown::paged_table()
```

```{r message=FALSE, warning=FALSE}
povzetek <- summary(corp)
povzetek
```

## Seznam nezaželenih besed

```{r}
stop_sl <- stopwords(language = "sl", source = "stopwords-iso")

stop_sl <- c(stopwords(language = "sl", 
                       source = "stopwords-iso"), "\n", " ")

```

Odstranjujemo. 

```{r}
besede <- tokens_select(toks, pattern = stop_sl, 
                       selection = "remove", padding = FALSE)
```


## Kwic konkordance

V poizvedbenem nizu je mogoče navesti en izraz ali tudi več. Če je navedenih več izrazov (tj. 2 ali več), potem potrebujete povezovalno funkcijo `c()`, ki povezuje več nizov v en funkcijski argument. 

Konkordanco lahko uporabljamo tudi z nekaterimi grafičnimi funkcijami knjižnice `quanteda` (npr. `textplot_xray()`). 

```{r}
conc <- kwic(toks, pattern = c("ura", "tišina"))
conc

textplot_xray(conc)
```

Izboljšan izpis tabele omogoča funkcija `as_tibble()` iz knjižnične zbirke `tidyverse`. Tabelo lahko preoblikujemo s funkcijami `tidyverse`, ni pa uporabna za funkcije knjižnice `quanteda`. 

```{r}
kwic(toks, pattern = c("ur*", "tišin*"), 
     case_insensitive = TRUE) %>% 
  as_tibble() %>% 
  rmarkdown::paged_table()

```


```{r}
kwic(corp, pattern = phrase("dobr* d*"), window = 2)

kwic(corp, pattern = phrase("dobr* d*"), window = 5, 
     case_insensitive = TRUE) %>% 
  as_tibble() %>% 
  rmarkdown::paged_table()

```


```{r}
kwic(toks, "*ica", valuetype = "glob", 
     case_insensitive = FALSE) %>% 
  as_tibble() %>% 
  group_by(docname) %>% 
  count(keyword, sort = TRUE)
```

```{r}
kwic(toks, pattern = c("\\b.*[nl]ica\\b"),
     valuetype = "regex", 
     case_insensitive = FALSE) %>% 
  as_tibble() %>% 
  rmarkdown::paged_table()
```

```{r}
kwic(corp, pattern = phrase("dob[r]?.* d.*"),
     valuetype = "regex", 
     case_insensitive = FALSE) %>% 
  as_tibble() %>% 
  rmarkdown::paged_table()
```

Opcija `window` nam izpisuje navedeno število besed (pojavnic, tokens) na levi in desni strani ključne besede, privzeto po pet besed. 

Če želimo v konkordanci na levi in desni strani ključne besede izpisati cele povedi, potem lahko s knjižnico `quanteda` ustvarimo korpus povedi z ukazom `corpus_reshape()` (namesto besednih pojavnic). Druga možnost je, da uporabljamo kar funkcijo `tokens()` namesto `corpus_reshape()`. Poizvedbo opravimo na osnovi korpusa povedi in s pomočjo regularnih izrazov. Razmik (`window`) nastavimo na 1. 

```{r}
# ustvari jezikovno gradivo povedi
corps <- corpus_reshape(corp)
# ali seznam povedi
tokss <- tokens(corp, what = "sentence")

# regex \\b pomeni rob besede (border)
kwic(tokss, pattern = "\\bdobro\\b", 
     window = 1,
     valuetype = "regex", 
     case_insensitive = FALSE)

kwic(tokss, pattern = "\\bdobro\\b", 
     window = 1,
     valuetype = "regex", 
     case_insensitive = FALSE) %>% 
  as_tibble() %>% 
  rmarkdown::paged_table()
```


## Pogostnost

```{r}
matrika = dfm_select(mat, selection = "remove", 
                     pattern = stop_sl, padding = FALSE)
matrika
```

maj68-0073	Vladimir Kavčič (1932)	
maj68-0147	Tone Partljič (1940)

```{r}
pogostnost <- textstat_frequency(matrika, groups = c("maj68-0073", "maj68-0147"))

pogostnost <- textstat_frequency(matrika, groups = c("Kavčič", "Partljič"))

pogostnost %>% 
  group_by(group) %>% 
  filter(str_detect(feature, "^[:alpha:]")) %>% 
  # filter(group == "Partljič") %>% 
  slice_head(n = 5) %>% 
  rmarkdown::paged_table()

```

```{r}
pogostnost %>% 
  group_by(group) %>% 
  filter(str_detect(feature, "^[:alpha:]")) %>% 
  slice_head(n = 5) %>%
  pivot_wider(names_from = feature, values_from = frequency,
              values_fill = 0) %>% 
  rmarkdown::paged_table()

```

```{r}
pogostnost %>% 
  filter(str_detect(feature, "^[:alpha:]")) %>% 
  slice_max(order_by = frequency, n = 20) %>% 
  mutate(feature = reorder_within(feature, frequency, frequency, sep = ": ")) %>%
  # ggplot(aes(frequency, reorder(feature, frequency))) +
  ggplot(aes(frequency, feature)) +
  geom_col(fill="steelblue") +
  labs(x = "Frequency", y = "") +
  facet_wrap(~ group, scales = "free")

```


## Kolokacije

```{r}
coll_2 = textstat_collocations(besede, size = 2:5, tolower = TRUE) # naredi male črke !

coll_2 %>% 
  rmarkdown::paged_table()

```


```{r}
rad <- coll_2 %>% 
  filter(str_detect(collocation, "rad$"))
rad %>% rmarkdown::paged_table()

```

```{r}
besede_caps = tokens_select(besede, pattern = "^[A-Z]", 
                                valuetype = "regex", 
                                case_insensitive = FALSE, 
                                padding = TRUE)

coll_caps2 = textstat_collocations(besede_caps, size = 2, 
                                   tolower = FALSE, 
                                   min_count = 2)

coll_caps2 %>% rmarkdown::paged_table()

```


## Položaj v besedilu

```{r}
kwic_majda = kwic(besede, pattern = "Majda")
textplot_xray(kwic_majda)

```

```{r}
kwic_mesto <- kwic(besede, pattern = "mest*")
textplot_xray(kwic_mesto)

```


## Slovarska raznolikost besedil

```{r}
textstat_lexdiv(matrika, measure = "all") %>% 
  rmarkdown::paged_table()
```

## Podobnost besedil

Naslove besedil v jezikovnem gradivu potegnemo iz zgoraj sestavljenega seznama *df_dolzina*. 

```{r}
df_naslovi <- df_dolzina[c(2, 8, 9), ] %>% 
  pull(title_disp)
df_naslovi
```
Sestavimo tabelo z novim izborom proznih del, tokrat s tremi literarnimi deli.  

```{r}
df_izbor3 <- df %>% 
  # ohranimo le tri prozna dela iz celotne tabele 
  filter(title_disp %in% df_naslovi)

df_izbor3 %>% rmarkdown::paged_table()
```

Sestavimo nov corpus, seznam pojavnic in matriko dokumentov in pojavnic. 

```{r}
corp3 <- corpus(df_izbor3, 
               text_field = "text", docid_field = "doc_id")
toks3 <- tokens(corp3, remove_numbers = TRUE, remove_punct = T,
               remove_symbols = T, remove_url = T, 
               remove_separators = FALSE)
mat3 <- dfm(toks3, padding = TRUE)
```

Programska funkcija `textstat_simil()` iz knjižnice `quanteda` omogoča izračun količnika podobnosti besedil. Ena izmed priljubljenih metod je kotna funkcija kosinusove razdalje - `cosine`. 

Če je kosinus = 1, sta besedili povsem enaki, če je kosinus = 0 povsem različni. 

```{r}
textstat_simil(mat3, method = "cosine", margin = "documents")
```

Namesto kosinusa lahko uporabljamo tudi druge metode. Privzeta je korelacija:   
"correlation" (default), "cosine", "jaccard", "ejaccard", "dice", "edice", "simple matching", and "hamann".

```{r}
textstat_simil(mat3, method = "dice", 
               margin = "documents")
```

Razlike med besedili so majhne, saj se večina besednih oblik (tj. funkcijske besede) pojavlja v vseh treh besedilih. 

Nasprotna funkcija je `textstat_dist()`, ki meri različnost besedil. Privzeta metoda je evklidska razdalja (znana tudi kot pitagorejska razdalja ali hipotenuza v pravokotnem tritkotniku:   
"euclidean" (default), "manhattan", "maximum", "canberra", and "minkowski".

Narišemo lahko tudi *dendrogram*, in sicer s funkcijo `hclust()`, ki se naloži v pomnilnik ob zagonu programa `R`. 

```{r}
# plot a dendrogram after converting the object into distances
dist1 = textstat_dist(mat3, method = "euclidean", 
                      margin = "documents")
plot(hclust(as.dist(dist1)))
```


## Ključne besede

Metod za določitev ključnih besed v besedilih je veliko. V knjižnici `quanteda` (zdaj že nekaj časa posebna knjižnica `quanteda.textstats`) najdemo hitro in preprosto funkcijo `textstat_keyness()`.

```{r message=FALSE, warning=FALSE}
df_izbor

key_kavcic <- textstat_keyness(matrika, target = "maj68-0073")
key_kavcic %>% rmarkdown::paged_table()

key_partljic <- textstat_keyness(matrika, target = "maj68-0147")
key_partljic %>% rmarkdown::paged_table()

```

Besedne oblike, ki so v primerjavi z drugim besedilom (ali besedili) najbolj značilne za določeno besedilo, imajo visoko vrednost hi kvadrata (*chi2*) in se na seznamu privzeto znajdejo na vrhu tabele, v proznih delih pogosto imena glavnih likov.  

S programsko funkcijo `textplot_keyness()` lahko tudi narišemo diagram z najbolj značilnimi besednimi oblikami primerjanih besedil. 

```{r message=FALSE, warning=FALSE}
textplot_keyness(key_kavcic)
textplot_keyness(key_partljic)

```


## Razumljivost besedila

Razumljivost besedila in s tem primernost besedila za določeno starostno skupino ali bralce z določeno stopnje izobrazbe ocenjujemo na osnovi različnih meril, med najpreprostejšimi in pogosto uporabljenimi sta dolžina povedi in dolžina besednih oblik. Knjižnica `quanteda` ponuja celo paleto merskih metod (gl. vgrajeno pomoč, `help`):   

```{r}
textstat_readability(corp, measure = c("Flesch", "Flesch.Kincaid", "FOG", "FOG.PSK", "FOG.NRI")) %>% 
  rmarkdown::paged_table()
```

Višji koeficient *Flesch* pomeni, da je izrazna plat besedila bolj zahtevna. Za angleščino so izdelali priporočila za potencialne skupine bralcev (npr. ali je besedilo z določeno indeksno vrednostjo jezikovno primerno za otroke 5. razreda osnovne šole).  

<https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests>

Za uporabo v slovenščini je treba formule za izračun koeficientov prilagoditi. 


## Kookurenčna mreža (FCM)

Katere besedne oblike se pogosto sopojavljajo, je mogoče prikazovati v mrežnih diagramih. 

Iz matrike dokumentov in besednih oblik (`dfm`) izberemo ustrezne besedne oblike za prikaz povezanosti. Za izbor uporabljamo programsko funkcijo `dfm_select()`.   

Ukaz `topfeatures()` sestavi seznam najpogosteje nastopajočih besednih oblik, funkcija `names()` potegne besedne oblike iz seznama imen in pogostnosti pojavljanja. 

```{r}
dfm_tags <- dfm_select(
  # omejujemo na matriko drugega besedila
  matrika[2,], 
  # katere besede želimo vključiti
  pattern = (c("jože", "tomaž", "beti", "veronika", "poslanec", 
               "majda", "miro", "danica", "rekel", "žena", 
               "železnik", "vino", "kavo", "mož", "otrok", 
               "upravitelj", "gostilno")))

toptag <- names(topfeatures(dfm_tags, 50, decreasing = TRUE))
head(toptag, 10)
```


```{r}
#| out-width: "100%"
#| out-height: "100%"

# Construct feature-cooccurrence matrix (fcm) of tags
fcm_tis <- fcm(matrika[2,]) # besedilo 2 je Tišina
head(fcm_tis)

top_fcm <- fcm_select(fcm_tis, pattern = toptag)

textplot_network(top_fcm, min_freq = 0.1, 
                 edge_alpha = 0.8, edge_size = 5)
```

```{r}
png("pictures/textplot_network_partljic.png", 
    width = 700, height = 500,)
textplot_network(top_fcm, min_freq = 0.1, 
                 edge_alpha = 0.8, edge_size = 5)
dev.off()
```



Kookurenčno matriko (`fcm`) lahko pretvorimo v tabelo za uporabo s programskimi funkcijami `tidyverse`. Uporabljamo `as_tibble()` ali v novejšem času `convert()`. 

```{r}
cooc_tabela <- fcm_tis %>% as_tibble()
cooc_tabela <- fcm_tis %>% convert(to = "data.frame")
head(cooc_tabela)
```

Kookurenčne tabele po navadi dopolnjujemo z merami asociacije, ki nam povedo, kako močno sta izraza povezana in ali je povezanost nenaključna. 


